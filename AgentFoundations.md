# 1 AGENT 综述 （从底层科学出发，思考Agent未来）

FROM BRAIN-INSPIRED INTELLIGENCE TO EVOLUTIONARY, COLLABORATIVE, AND SAFE SYSTEMS

从脑科学智能 到 进化论、协作以及安全系统

本文综述，从脑科学出发，讲述应用并融合多元思维，包括认知科学、神经科学、计算研究等。

本文从四部分讲述：

1. 智能体的各个基础模块
2. 自我增强和自适应进化机制
3. 协作和进化的多智能体系统
4. 构建安全、可靠且有益的AI系统

## Intro

Agent 定义：

describes an agent as “anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators”

“任何能够通过传感器感知其环境，并通过执行器对环境进行作用的东西。”

即 感知者 + 行动者 + 动态。

再添加限制条件：自主性 + 适应性 + 真实世界交互

观点：这种适应性，加上其流畅的对话能力，使得LLM驱动的智能体能够作为人机之间的智能中介，在日益复杂的工作流中，将人类意图与机器执行精准结合。

【即 AI 成为人和机器之间的中介，将人类意图与机器执行精准结合。所以叫 Agent!代理！】

---

### 表 1.1：人类大脑/认知与LLM智能体的简要高层比较

| 维度 | 人类大脑/认知 | LLM智能体 | 备注 |
| :--- | :--- | :--- | :--- |
| 硬件与维护 | - 生物神经元、神经递质、神经可塑性。<br>- 需要睡眠、营养、休息。<br>- 知识转移主要通过学习，复制能力有限。<br>- 极其节能（约20瓦）。 | - 深度神经网络，基于梯度的优化。<br>- 需要硬件、电力与冷却系统。<br>- 可在全球范围轻松复制到服务器上。<br>- 能耗高（每台GPU服务器数千瓦）。 | 人类大脑是生物维护的、能效高且不易复制的；LLM智能体依赖硬件维护，易于复制，但能效远低于人脑。 |
| 意识与发展 | - 具有真正的主观体验、情感与自我意识。<br>- 从儿童期起，经历渐进的发展阶段。<br>- 情感认知驱动决策过程。 | - 无真正的主观体验或自我意识。<br>- “情感”仅是表面的语言模仿。<br>- 训练后基本静态，动态成长受限。 | 人类意识源于情感、社会和生物发展；LLM仍然是静态的，缺乏真正的内省或情感深度。 |
| 学习方式 | - 终身、连续、在线学习。<br>- 少样本学习、快速知识迁移。<br>- 学习受环境、文化和情感影响。 | - 主要是离线、批量式训练。<br>- 在线微调与适应能力有限。<br>- 中性、无情感的知识学习。 | 尽管通过指令微调（instruction tuning）有所改进，人类学习依然更具动态性、适应性，并深度融合文化与情感，比LLM学习更复杂。 |
| 创造力与发散性 | - 根植于个人经验、情感和潜意识洞见。<br>- 丰富的跨领域联想和隐喻性思维。<br>- 情感深度对创造力有重要影响。 | - 基于大量数据的统计重组。<br>- 通过概率优化实现创新。<br>- 缺乏丰富的情感和经验基础。 | LLM的创造力是统计性和数据驱动的；人类创造力则融合了情感、经验与潜意识过程。 |

---

【总】：人的能耗低，情感和创新性强，适应性，少样本，终身学习。AI 耗能高，大量数据统计重组，

---

### 大脑区域功能与人工智能的类比

以下是根据大脑模块和功能对比AI的总结表格：

| **大脑模块**    | **功能**                                           | **AI对比**                                              |
|----------------|--------------------------------------------------|--------------------------------------------------------|
| **额叶**       | 执行控制、决策、逻辑推理、工作记忆、自我意识、认知灵活性、抑制控制 | 规划与决策（L2），工作记忆（L2），灵活性和自我意识（L3）仍然欠缺，抑制控制未充分探索 |
| **顶叶**       | 空间定向、注意力、多感官整合、传感-运动协调        | 空间定向（L2），注意力（L2），SLAM技术用于机器人学，触觉感知（L3）尚未探索   |
| **枕叶**       | 视觉感知                                         | 基本视觉识别（L1）非常强，场景理解与视觉推理（L2）仍有挑战                       |
| **颞叶**       | 听觉处理、语言理解、记忆形成、语义理解            | 语言处理（L1）先进，但情节记忆和终身学习能力有限（L2），语义理解仍在探索中   |
| **小脑**       | 运动协调、技能学习、错误修正、认知时序            | 运动协调（L2）和技能学习（L2）在机器人学中有进展，认知时序（L3）仍是新兴领域 |
| **脑干**       | 自主调节、反射控制                               | 自动刹车等简单反射性反应（L1），自主调节（L3）尚未探索                       |
| **边缘系统**   | 情绪处理、奖励机制、共情、动机驱动、压力调节       | 强化学习模仿奖励机制（L2），情绪理解和共情（L3）不足，伦理问题存在               |

此表格总结了大脑各个模块的功能以及目前AI在这些领域的对比情况。

【总】：

L1 表示 AI已经能模仿甚至超越人类，比如视觉和听觉处理、语义处理、简单反射。

L2 表示尚未成熟，只能接近人类。比如 AI 在规划、决策、工作记忆方面已经有应用，但上升空间很大，还有终身学习、强化学习模仿奖励机制。 

L3表示研究正在初步，几乎没有探索，比如：触觉感知、认知时序、自我调节、情绪共情。

---

缺点：现在的 Agent 框架零散混乱，没有高效利用规划、决策、记忆。

【总】：一个缺口，就是一个增量，所以现在 RL 很火。基座模型如何扩展为Agent，自我调节不够，规划、决策、记忆也还不够，所以有 RAG，function call等等。

### 生物学合理性构建 “统一的” Agent

不同于传统的 感知 + 行动。

接下来，通过生物学合理性，提出一个构建 unified 统一的 Agent 框架的可能性。

重点在：感知–认知–行动循环的统一智能体架构（perception–cognition–action）。

这里出现了明斯基(上个世纪的图灵奖得主)的《心智社会》（Society of mind）、布祖基的内外观视角（the brain inside out）和贝叶斯主动推理（Action and behavior: a free-energy
formulation）。去读一读原著！！！


我们的架构在三个概念层次上运行：社会、环境和智能体。

智能体进一步分解为三个主要子系统：感知、认知和行动。

在认知中，我们识别出关键子模块：记忆、世界模型、情绪状态、目标、奖励、学习和推理过程（包括作为推理产生的特殊行为的“规划”和“决策”）。注意力主要在感知和认知中处理。

这个定义突出了三个区分基础智能体的基本支柱：

持续的自主性（独立运作以实现长期目标，无需逐步的人工干预）、适应性学习（通过多样的经验不断演化内部表示）、有目的的推理（生成由复杂、内部维持的目标和价值观指导的行为）。

因此，基础智能体通过整合深层次的认知结构、多模态处理能力和积极的、持续的自我优化，代表了从传统智能体向一个新的方向的根本转变，使它们能够在广泛的环境和领域中有效运作。

与经典定义通常仅将智能体框定为简单的感知-行动循环（“感知并行动”）不同，我们对基础智能体的定义强调了内部认知过程的深度和整合。

基础智能体不仅感知环境并执行即时行为，而且还具有不断发展的、目标导向的认知——持续适应记忆结构、世界模型、情绪和奖励状态，并通过推理自主优化策略。这种内部认知的丰富性使得基础智能体能够自主地将复杂、抽象的目标分解为可操作的任务，战略性地探索环境，并动态调整其行为和认知资源。

因此，我们统一的感知–认知–行动框架显式地建模并纳入了这些复杂的认知能力，认识到内部（心理）行为与外部（物理或数字）交互同等重要，促进了从物理机器人到基于软件或纯文本的智能体等各种表现形式。


### 与现有理论的联系

1. 提出的传统感知–思考–行动循环，加入了注意机制（在P模块中）、学习和情感（在C模块中），以及持续存在的奖励信号。这种明确性使得我们能够更容易分析智能体的内部状态和先前的行动如何塑造后续的感知和认知。

2. 明斯基的“心智的社会”：
在更广泛的“社会”背景中，每个智能体（或子智能体）可以协作或竞争，就像明斯基的内部机构一样。近期的基于自然语言的心智社会工作[31]支持智能体系统可以使用原始的心智社会理论表示，并可以纳入智能体之间的社会结构和经济模型。

3. 布兹萨基的内外观观点 （brain from inside out）

脑是主动构建和更新其感知，而不仅仅是接收输入。

这支持了“内外观”立场，即智能体的内部上下文推动它的环境采样和解读方式，而不是被动地对环境作出反应。

4. 部分可观察马尔可夫决策过程（POMDP）

我们的框架可以被视为经典部分可观察马尔可夫决策过程（POMDP）的一个推广。

每个子组件（记忆、世界模型、情感、目标、奖励）都被明确建模并更新，模拟了生物学启发的认知观点。因此，尽管我们的方法通过强制实施概率T、标量奖励和最小心理状态，恢复了POMDP公式作为一个特例，但它允许更丰富的环境转移、内部状态和决策机制。

5. 主动推理与贝叶斯大脑



