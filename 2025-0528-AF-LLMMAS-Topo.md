#

以下是您提供英文内容的中文翻译：

---

**（a）集中式 （b）分布式 （c）层级式**
图14.1：多智能体协作的不同拓扑结构类型。

**（a）协作 （b）竞争**
图14.2：协作与竞争的智能体。

---

本节探讨基于大语言模型（LLM）的多智能体系统（MAS）中的交互类型及其对通信、协作和任务执行的影响。我们首先分析静态拓扑结构——即连接模式由领域知识预先确定；随后探讨动态（自适应）拓扑结构，其根据性能指标、工作负载变化或策略约束来调整智能体之间的连接。最后，我们讨论在系统成本、性能与鲁棒性之间取得平衡时的可扩展性挑战与权衡，参考了分布式处理、自组织与协同行为涌现方面的最新研究成果。

---

### 14.1.1 静态拓扑结构

静态拓扑结构由预设的结构模式决定，在系统执行期间基本保持不变。在这些配置中，智能体之间（或与中心协调者之间）的连接通过固定规则和启发式方法建立，从而确保可预测的通信流程和简化的协作。三种典型结构通常被讨论：层级式（hierarchical）、分布式（decentralized）和集中式（centralized）架构。

#### 层级式结构

层级式拓扑将智能体按照等级关系排列，高层智能体负责协调或监督底层智能体。这种方式类似于传统的管理框架，例如标准操作流程（SOP）或瀑布模型，其中任务被分解为顺序且明确的阶段。例如，AutoAgents \[1008] 框架通过设定角色（如规划者、智能体观察者、计划观察者）来综合执行计划；而 ChatDev \[983] 则利用层级任务分解来简化软件开发 \[626, 921, 627]。尽管层级结构便于调试、性能监控和模块化开发，但当高层智能体负载过重时，可能会形成瓶颈 \[1011]。近期在叙事生成 \[1012–1014] 和数据科学应用（如数据清洗 \[1015–1016]、可视化 \[1017–1018] 及自动机器学习 \[1019–1020]）方面的研究，揭示了在保持一致性的同时，如何平衡适应性与实时行为的涌现。

#### 分布式结构

在分布式拓扑中，智能体以点对点方式互动，没有中心协调者，网络通常建模为链状、环状、小世界或随机图 \[1021, 971]。该结构具有更强的容错性，因为单个智能体的失效不会导致系统瘫痪。例如，\[1022] 展示了将图推理任务分配给多个智能体有助于突破单个 LLM 的上下文长度限制。\[1023] 进一步提出了分解策略，使得主控 LLM 能够高效地委派子任务。但在这种结构中，要保持全局一致性则需依赖复杂的共识与同步协议。

#### 集中式结构

集中式拓扑依赖一个主协调者收集信息并分层指挥外围智能体。这种架构便于统一资源管理和共享全局视图，如文化公园和 Lyfe Agents \[1024, 1025]。但当智能体数量增多时，中心节点可能成为瓶颈，带来通信开销增加和故障风险。目前关于协调者-智能体配置的研究 \[971] 以及在集中结构中实现自治能力的研究 \[1026] 均指出，在保持一致性的同时，集中架构存在可扩展性和灵活性不足的问题。

**总结**：
静态拓扑结构的优点在于确定性与预设性。预定义的结构模式使系统通信流程可预测，智能体之间协作高效。此类拓扑通常基于结构性知识或静态规则，适用于任务流程固定、角色预设、系统需求清晰的场景。其第二大优点是设计、实现和维护相对简单，资源调度和模块化也更方便。然而，静态拓扑缺乏灵活性，无法响应实时变化，不能应对突发状况，如智能体故障、任务复杂度变化或系统目标调整。这种实时响应能力的缺失限制了运行时的系统重构，在动态环境中会降低系统效能。

---

### 14.1.2 动态与自适应拓扑结构

虽然静态拓扑结构提供了确定性和可预测性，并且在稳定任务和角色明确的场景中表现良好，但它们并不适用于开放式或新颖任务场景。现实应用中，如实时协作计划、动态社会模拟等，往往要求智能体在任务推进、资源变动或环境反馈中调整交互方式。这种对结构的自适应性需求催生了动态拓扑结构，它们在运行时根据性能反馈、工作负载或战略约束重塑智能体之间的关系，从而在一致性与响应性之间实现平衡。

例如，DyLAN 框架 \[725] 通过两步推理过程支持推理时的智能体选择：先进行前向-反向的团队优化并生成无监督的智能体重要性得分，随后在运行时动态重组团队。OPTIMA \[1027] 则通过“生成-排序-选择-训练”的迭代框架优化智能体连接，利用奖励函数在任务质量、token 效率和可读性之间进行平衡，同时通过直接偏好优化等策略优化通信行为。MAD 框架 \[649] 通过提示阶段、结构和角色的联合优化展示了灵活性，例如在剪枝空间中动态分配验证者与辩论参与者等角色。

技术进步也使拓扑控制变得可行。GPTSwarm \[651] 将智能体视为计算图，并通过演化策略和强化学习来调整邻接矩阵，以任务反馈优化节点。MACNET \[1028] 采用有向无环图结构，由监督指导者管理边，执行助手管理节点，适用于更复杂的协调任务，支持通过拓扑排序实现敏感的通信传播。

在特定应用中，也有多样化架构的案例。例如，DAMCS \[1029] 在开放世界中结合分层知识图谱（A-KGMS）和结构化通信方案（S-CS），实现基于上下文消息传递的协同规划。AutoAgents \[1030] 采用动态起草-执行流程，多个预设智能体共同制定专家团队，适用于小说创作等创意场景，其并行处理与内部监督机制尤为高效。

在图推理方面，MACNET \[1028] 的小世界发展与 \[1022] 中的结构化协作理念相呼应，绕过单个 LLM 的局限。在协作任务求解方面，也涌现出若干基于动态拓扑的新范式，如搜索驱动方法、基于 LLM 的生成方法及利用外部参数的方法。

#### 搜索驱动方法

不少研究采用搜索方法迭代优化通信结构。例如，ADAS \[741] 使用 Meta Agent Search 算法，在代码空间中生成并测试新型智能体设计，归档优越结构并优化后续策略。Aflow \[773] 将每次 LLM 调用建模为图中的节点，利用蒙特卡洛树搜索（MCTS）动态扩展和优化任务流程。MAD \[1031] 和 OPTIMA \[1027] 也采用类似的“生成-排序-选择-训练”策略，借鉴了 MCTS 原理，在任务质量与效率间取得平衡。

#### 基于 LLM 的生成方法

作为补充，一些新近研究直接利用 LLM 的生成能力构建并调整动态拓扑。例如，Dylan \[725] 引入时间前馈网络（T-FFN）模型，将每次通信视为一个网络层，通过前向-反向传播计算智能体重要性分数以动态选队。相关研究包括 DAMCS \[1029]、AutoAgents \[1030] 和 TDAG \[1032]，它们动态生成子智能体或更新分层知识图谱，以实现协同规划与任务分解。AutoFlow \[773] 和 Flow \[1033] 则将任务流程建模为自然语言程序或活动图（AOV），通过强化学习信号不断优化。ScoreFlow \[788] 更进一步使用梯度优化（基于 loss 的梯度）持续重构智能体工作流。

#### 外部参数驱动方法

由于微调 LLM 智能体的成本高，部分研究主张通过训练与 LLM 无关的外部参数来配置智能体拓扑结构。例如 GPTSwarm \[651] 将拓扑结构建模为有向无环图（DAG），仅训练边权重作为系统中唯一的可调参数。AgentPrune 则提出了一个统一的建模框架，从时空图视角识别通信冗余边并进行剪枝。后续研究如 G-Safeguard \[1034] 同样在 MAS 系统外部训练图神经网络（GNN）来识别并消除恶意通信路径。尽管这类方法参数高效，但其小规模参数空间和与 LLM 的低耦合性在一定程度上限制了性能提升。

---

**讨论**

动态拓扑结构不仅用于任务求解，还在模拟复杂社会互动中发挥关键作用。近期综述 \[975] 指出，基于 LLM 的智能体模型能够进化其连接关系，以应对自治变化、社会行为及环境反馈。例如，\[50]、OASIS \[936] 和 ProjectSid \[989] 模拟了动态社会网络。\[50] 通过自然语言生成的记忆检索机制根据智能体经验调整社会关系；OASIS 构建实时社交媒体环境，用户关系和信息流不断更新；Project Sid \[989] 则在 Minecraft 环境中利用 PIANO（并行信息聚合与神经编排）架构实现了1000多个 AI 智能体的实时互动，涌现出专业化角色、规则遵守、文化与宗教传播等复杂社会结构。AgentScope-scalability \[1035] 和 Social Survey \[975] 等架构支持大规模多智能体模拟，用于研究文化传播、集体决策和群体行为涌现。此外，动态拓扑还应用于医学和开放领域的具身智能任务中，如 AI 医院 \[1036] 和 agent 医院 \[921] 模拟真实医疗流程，通过诊断、治疗与反馈的迭代循环不断重构沟通路径。IOA \[933] 等框架支持异构跨设备交互，实现现实场景下的动态团队组建与任务分配。

尽管上述动态多智能体拓扑在性能上取得了显著进展，仍面临以下三方面的限制，未来研究应重点关注：

**（1）泛化能力**：当前的 MAS 拓扑结构通常针对单一任务域进行优化。例如，AFlow \[773] 专注于数学或代码基准下的搜索与优化，生成的固定流程难以迁移到新任务领域……（未完）

---


以下是该段英文内容的中文翻译：

---

### 14.2 可扩展性考虑

可扩展性是在基于大语言模型（LLM）的多智能体系统（MAS）中面临的一项关键挑战，尤其是在智能体数量增加的情况下。

在全连接网络中，通信路径的数量呈二次增长，导致通信量爆炸，进而增加了 token 使用量和计算成本 \[1037, 626]。集中式和分层拓扑结构中，当监督节点收到大量消息时，可能会出现同步瓶颈；而去中心化网络虽然容错性更强，但需要复杂的共识算法以实现一致的全局状态。

近期的研究如 \[1028] 表明，当多智能体协作结构采用有向无环图（DAG）时，系统可以高效扩展至上千个节点而不会出现明显的性能下降。同样，\[1022] 显示，将图推理任务分布给多个智能体可以避开长文本输入和上下文长度限制所带来的瓶颈。此外，关于自组织智能体的研究 \[1038] 显示，动态复制和任务分配可以在保持每个智能体工作负载恒定的同时提升整体处理能力。最后，\[1039] 提出的多维分类法为分析智能体自主性与一致性之间的权衡提供了有价值的框架，有助于在集中控制与去中心化灵活性之间取得平衡，从而优化可扩展性。

除了这些基础性研究，近年来在实际多智能体平台设计方面的进展也进一步丰富了可扩展性的讨论。例如，AgentScope \[1035] 提供了一个面向开发者的平台，基于 actor 模型的分布式框架，可实现本地与分布式部署之间的无缝迁移。其统一的工作流和自动并行优化显著降低了随智能体数量增加而出现的通信开销和同步难题。通过引入容错机制和智能消息过滤，AgentScope 展示了如何通过系统级支持，在动态和异构的部署环境中仍保持良好性能。

另一个补充性的方案来自 Project Sid \[989]，其研究重点在于模拟智能体文明中的可扩展性。在这里，关注点从孤立的任务求解转向复杂社会动态的模拟。提出的 PIANO 架构（通过神经协调的并行信息聚合）通过将较慢的认知过程与快速的反应模块解耦，使智能体能并行运行。专门引入的认知控制器确保多个并行输出之间的一致性。该设计不仅实现了从小规模群体到上千智能体的扩展，还有效应对了高频交互中固有的协调难题。

在更大规模的可扩展性方面，AgentSociety \[1040] 展示了一个全面框架，能够模拟包含多达一万个智能体的现实社会环境。通过将基于 LLM 的社会生成智能体集成到真实的城市、社会和经济背景中，AgentSociety 利用分布式计算和高性能消息系统（如 MQTT）来支持每天数百万次的交互。该平台展示了新兴的混合架构如何通过有效管理通信成本、协调开销与涌现行为的真实性之间的权衡，来支撑宏观层面的现象，例如经济市场动态、舆论传播和城市规划模拟。

尽管从理论上扩大智能体规模具有明显优势，但仍有必要质疑：大规模部署智能体是否对所有任务求解场景都具有价值？虽然总体计算能力随智能体数量而增长，但当考虑到内存开销和智能体间通信成本时，新增智能体的边际效益可能呈递减趋势。这一现象源于一个基本约束：整体工作量是单个任务复杂度与任务划分程度的乘积，但协调成本往往会随着智能体数量以超线性方式增长。因此，对于许多有边界的问题域来说，可能存在一个最优的智能体数量，超过该阈值后，性能不仅不再提升，甚至可能因协调开销过高而下降。

相反，在以模拟复杂社会动态、涌现行为或大规模群体智能为目标的场景中，扩展至大量智能体不仅有益，甚至是必要的。在这些背景下，研究重点从优化任务求解的计算效率转向精确再现或预测微观交互中产生的宏观模式。这类模拟通常涵盖经济市场行为、社交网络演化以及城市基础设施规划等领域，为捕捉现实的群体级现象，往往需要应对庞大智能体规模带来的计算开销。

结合集中控制与去中心化子团队的混合架构，为应对这些可扩展性挑战提供了有前景的解决方案 \[921, 918]。在这类设计中，监督智能体负责全局目标和协调，而执行智能体聚焦于具体子任务的完成。这种层级组织有助于缓解任何单点的信息过载问题，并可根据任务需求动态调整团队规模，从而优化资源利用。此外，图搜索算法、基于强化学习的更新策略和进化方法等先进技术对于随着系统扩展而迭代优化网络结构至关重要。智能消息过滤、优先级管理与聚合机制可大幅降低通信开销，同时保持良好的智能体协作质量。此外，异步通信协议和部分知识共享策略也显示出在维持智能体之间足够全局认知的同时，降低协调瓶颈的潜力。

**关于可扩展性的总结**

总的来说，基于 LLM 的多智能体系统在系统拓扑结构与可扩展性方面展示出多样化的设计选择——从提供简洁性和可预测性的静态结构，到具备灵活性和适应性的动态架构。尽管一些基础研究（如 \[1028]、\[1038]）强调了可扩展图结构和自组织原则，但像 AgentScope、Project Sid 与 AgentSociety 这样的实践平台也表明，通过集成的分布式框架、并发处理机制以及现实环境模拟，可以协同应对多智能体系统的扩展挑战。可扩展性需求因任务求解与仿真模拟场景而异，这突显出多智能体架构中面向特定目标设计的重要性。随着研究的持续推进，开发更复杂的自适应算法、分布式架构和多维评估框架，将是提升基于 LLM 的多智能体系统可扩展性与实际可行性的关键。

**第15章 协作范式与协作机制**

本章深入探讨多智能体系统（Multi-Agent Systems, MAS）中智能体之间有目的的交互行为，分析其中一个智能体如何影响整体协作。我们借鉴人类社会结构中多样的交互行为，通过交互目的、交互形式以及所形成的关系来进一步解释多智能体协作。

MAS 指多个智能体在共享环境中进行交互，自主地作出决策以协同完成任务或相互竞争 \[1041]。本章聚焦于协作现象，因为它广泛存在于大多数实际应用中。基本上，MAS 中的每个智能体都具有不同的角色、初始知识和各自的目标。

在解决问题或交流过程中，智能体会与其他智能体或环境交互，以收集和处理信息，基于其目标、已有知识和观察结果独立作出决策，并随后执行相应操作 \[975, 1041, 1042, 1043]。知识、记忆与环境观察构成了智能体的信念，而多样化的动机则影响其任务处理方式和决策过程 \[1041]。因此，解决问题的有效性依赖于多样化的有目的交互形式，包括智能体之间（Agent-Agent）和智能体与环境之间的交互。这些交互可能是多轮的，且方向多变，具体取决于系统设计。

---

### 15.1 智能体之间的协作

在探讨 MAS 协作分类时，我们关注的是更细粒度的划分，以捕捉复杂多智能体交互中的细微动态。具体地，我们将智能体间的交互分为四种类型，这一分类受到人类社会互动模式的社会学洞察启发，并将其应用于 MAS 中的 Agent-Agent 交互。

人类社会中的交互模式包括：共识构建、技能学习、教学引导和任务分工协作等，这些社会学理论为智能体交互的分类提供了更精细的方法。这些交互形式构成了协作范式，使不同类型的智能体能够高效协同解决复杂问题。每一种协作范式对应于不同的合作、竞争、协调和决策挑战。

此外，MAS 实现中通常涉及多种交互类型的混合，而非单一类型或单向流程，从而形成随时间演化的复杂交互网络。在协作软件开发 \[626, 627] 中，例如：一位资深开发者智能体可能会与架构师智能体在任务层面协作，并通过多轮对话引导初级开发者智能体。他们共同进行代码审查并与测试专家智能体协作以提升测试覆盖率。

分析这些交互的目标与结果，有助于识别塑造智能体行为与决策的关键技术，从而更深入理解多智能体动态。

---

#### 共识导向交互（Consensus-oriented Interaction）

共识导向的交互关注于通过协商、投票和社会选择框架，使 MAS 达成统一目标 \[1044]。这种交互有助于整合多样的知识，并推动智能体朝着共同理解的方向调整其观点，从而实现共识 \[1045]。

此类交互使智能体整合知识以达成统一理解，对于在复杂问题中需要不同视角的集体决策极为重要。例如：MedAgents \[922]、MDAgents \[1046] 和 AI Hospital \[1036] 展示了多学科智能体通过协作对话增强推理能力并挖掘固有知识，从而提升问题解决能力。

这些对话使智能体将专业知识整合成一致输出，往往优于传统的 zero-shot 或 few-shot 推理方法。在科研环境中尤其明显，复杂问题的解决需要多元视角与精细验证。例如，Agent Laboratory \[746] 中博士与博士后智能体协作设定研究目标、解读实验并整合研究成果。Virtual Lab \[752] 则组织多个小组智能体开展科研工作，包括制定科研议题的集体讨论会和由单个智能体独立完成任务的会议。

实现多智能体共识的方法包括讨论、辩论、协商、反思和投票等结构化技巧。这些方法帮助智能体收集来自同行的输出，同时融合环境反馈（如数值数据与上下文信息），从而分享视角与假设，并逐步达成共识。

例如：

* **GPTSwarm \[651]**：通过图结构设计智能体之间的协作，信息流和边连接构成基本的群体讨论机制；若某个智能体反复输出错误意见，则将被排除。
* **RECONCILE \[918]**：采用圆桌式讨论格式，通过多轮对话和基于置信度的投票系统达成共识，并融合历史讨论经验、置信指标与人类洞察进行反思。
* **GOVSIM \[1048]**：智能体协作实现资源平衡，并建议共享资源以用于未来；其协商超越了简单的信息交换，强调关系型交互。
* **Multi-Agent Debate (MAD) \[1031]**：通过“你来我往”的方式展开辩论，并由法官裁定最终结果，以促进创造性思维。
* **Formal Debate 框架（FORD）\[1004]**：通过组织化的辩论增强语言模型之间的一致性，强模型引导共识，弱模型修正立场。
* **AutoAgents \[1030]**：定义了一种协同精炼动作（collaborative refinement action），每个智能体在对话过程中更新自身记录，同时补充对方的陈述，并精炼自身行动以达成共识。

---

**图15.1：基于大模型的 MAS 中四类智能体间协作类型总览：**

| 类型                               | 信息流          | 协作目的       | 知识整合水平    | 输出关注点 |
| -------------------------------- | ------------ | ---------- | --------- | ----- |
| **共识导向（Consensus-oriented）**     | 多向           | 统一目标、整合观点  | 高（多元专业知识） | 共享理解  |
| **协作学习（Collaborative Learning）** | 点对点          | 通过共享实现互相提升 | 中（个体经验）   | 技能增长  |
| **教学/指导（Teaching / Mentoring）**  | 单向（专家 → 初学者） | 传授知识与技能    | 低（已有知识）   | 学习者成长 |
| **任务导向（Task-oriented）**          | 顺序 / 流水线型    | 为共享目标协调行动  | 中（组合输出）   | 任务完成  |

---

以下是该英文内容的中文翻译：

---

### 协同学习交互（Collaborative Learning Interaction）

在协同学习中，交互通常发生在具有相似结构的智能体之间。尽管这些智能体在架构上相似，但由于各自的行为方式不同以及与环境的交互多样，它们积累了不同的记忆与经验。通过共同解决问题，这些智能体可以共享经验，从而增强其策略学习、任务解决和技能获取的能力。随着时间的推移，每个智能体都通过持续的交互提升技能，最终实现个体的演化。

协同学习与共识导向交互的关键区别在于其基本目标与过程。共识导向交互强调通过整合多样化的观点以达成一致，侧重于知识整合与信念对齐；而协同学习交互则强调同伴间的知识构建与经验共享，优先考虑彼此改进与个体成长。

在协同学习交互中，智能体通过观察他人的行为来更新自身的上下文或记忆。例如，智能体可以通过观察同伴的推理过程来学习最优策略，并据此调整自己的方法，而不一定需要达成某种“最佳”策略的一致意见 \[961–969, 971–972]。正如文献 \[966] 所指出的，有效的讨论策略显著影响智能体之间的学习效果。在这种交互中，智能体合作学习与解决问题，专注于彼此理解和提升，而非追求一致决策。这种方式通过持续的反馈来优化个体反应与知识。

常见的协同学习方法包括：

1. **经验共享**
   智能体交换个人见解与最佳实践。如文献 \[303] 所述，迭代式的经验优化使大语言模型（LLM）智能体在软件开发中不断通过团队经验的持续获取与利用，实现自适应的提升。MAS-CTC \[301] 是一个可扩展的多团队框架，支持团队之间在跨团队协作中交换决策与见解，并通过贪婪剪枝机制和聚合机制去除低质量内容，从而提升软件开发性能。MOBA \[1049] 中，基于多模态大模型的移动智能体系统让全局智能体反思局部智能体执行结果，以实现环境自适应规划。AutoAgents \[1030] 引入了知识共享机制，智能体之间交换执行结果，从而提升沟通与反馈效率，并可从他人处获取长期、短期及动态记忆。

2. **同伴讨论**
   同伴之间的讨论可以促使智能体表达推理过程，并从他人方法中学习。例如 MEDCO \[923] 创建了一个动态环境，通过学生智能体之间的协同问题解决来强化临床推理与决策能力。在 \[1050] 中，智能体在初始生成输出后开展结构化的讨论，逐步审查彼此的推理过程，通过反馈与信心评分机制，优化决策并提升推理准确性，促进协作知识获取。

3. **观察学习**
   智能体通过观察他人的行为与结果，调整自己的策略。AgentCourt \[1051] 设计的律师智能体在法庭辩论中通过积累经验不断改进其推理能力。在 iAgents \[1046] 中，智能体网络模拟了人类社交网络，主动交换完成任务所需的关键信息，从而克服信息不对称问题。其采用了 InfoNav 机制，引导智能体进行高效信息交换，并将人类信息组织为混合记忆，为交互提供全面准确的信息。实验也表明，在某些任务难度较高时，智能体会不断优化策略以获取必要信息。MARBLE \[948] 设计了一种认知演化规划方法，通过结合智能体的“预期”与实际执行结果来更新整体规划经验，以便更好地进行下一轮规划。

尽管协同学习交互带来了诸多益处，但也面临一些挑战，例如：如何在能力差异较大的智能体之间实现公平的知识交换、防止错误或偏见的传播、在促进学习的同时保持智能体的多样性，以及建立有效机制来让智能体基于相关性与可靠性选择性地吸收他人知识。要克服这些挑战，就需要精心设计交互框架与学习策略，平衡个体发展与系统整体进步。尽管知识公平性、偏差传播与可扩展性等问题存在困难，但协同学习在动态与复杂环境下提升多智能体系统（MAS）性能方面仍具有巨大潜力。通过迭代学习与机会提供，智能体能逐渐构建更丰富的知识库与更精细的问题解决能力。

---

**15.3 协同决策**

协同决策过程对于多智能体系统（MAS）的高效运作和任务成功完成至关重要。尽管协作本身就是多智能体系统的核心特性，但决策方法直接决定了协作的有效性以及系统的整体性能。最新研究强调了协同决策的重要作用。\[1037] 研究表明，多样化的决策方式可以显著提升系统的协作效率。\[649] 强调，一个合理的决策机制可以激发系统中智能的涌现。

从更广义的角度来看，协同决策过程可以根据其体系结构特征划分为两大类：**独裁式决策** 和 **集体式决策** \[1037]。

---

### **独裁式决策（Dictatorial Decision-Making）**

独裁式决策是指在 MAS 中由某一个智能体负责整个决策过程。在这种范式下，所有智能体会将其状态信息或本地观测结果发送给这个“独裁”智能体。该智能体负责整合这些数据，分析核心问题，并建立明确的决策指南。此方法的关键在于利用“全局思维”来提升决策质量，从而增强系统性能的可靠性并确保任务目标的达成。

相关研究如 \[1031, 1058, 1046] 展示了单一 LLM（大型语言模型）如何综合不同观点来做出更客观、全面的决策。此外，\[134, 1059] 提出了通过排序、打分或清单的方式进行加权整合，以增强决策过程的鲁棒性。不仅如此，\[1030, 1060] 提出了中央智能体将复杂任务拆解为多个简单子任务，并分配给按功能分组的专业智能体执行的体系结构。此外，在 \[651, 1028] 中，也存在一种思路：不是通过中央智能体，而是由拓扑结构中的最后一个节点智能体整合历史信息并进行推理得出结论。

---

### **集体式决策（Collective Decision-Making）**

集体式决策是指各智能体在没有中央权威的情况下，通过本地数据和交互（如投票或协商）共同做出决策。这种方法实现了决策权在各智能体间的共享，使系统具备更强的适应性，同时保持鲁棒性和可扩展性。

* **基于投票的决策（Voting-based Decision Making）**
  投票系统是集体决策中的关键机制，为达成共识提供了框架。\[1045, 968] 描述了如何通过投票达成多数共识。GEDI 投票模块 \[1037] 支持多种投票方式，有效提升了系统的推理能力和容错能力，同时避免了系统设计过于复杂。

* **基于辩论的决策（Debate-based Decision Making）**
  相较于投票机制，辩论型决策更注重智能体之间有组织的互动，以获得最优结果。\[1031, 1061] 中的智能体参与引导性讨论，提出方案并尝试解决分歧、调和不同观点。\[1050, 1062] 则通过通信通道进行多轮讨论、保持克制态度，从而达成共识。为解决“认知孤岛”问题，某些系统引入了公共检索知识库，让所有智能体在辩论过程中共享知识 \[1005]。通过模拟人类对话，这类系统使智能体能够交换视角，从而做出更有信息基础的决策。

---

### **讨论与未来工作**

多智能体系统（MAS）中的协作仍面临许多挑战，有待进一步研究。目前的方法大多依赖于上下文相关的交互，但尚未建立一套用于训练和优化协作行为的具体框架。这种对大型语言模型（LLMs）的高度依赖存在局限性，因为其效果本质上受限于 LLM 的上下文窗口大小和原生推理能力。虽然 LLM 为交互提供了良好基础，但这些系统仍受到上下文相关通信的固有限制。

未来的研究应关注于建立一种激发智能体主动学习的框架，尤其是关于**何时共享信息**与**如何共享信息**的策略。借助多智能体强化学习（MARL）的方法，亟需设计出帮助智能体判断信息共享时机与内容的策略，同时还需考虑信息通过何种通道传递。这不仅要求设计新的交互协议，还应结合训练机制，不断优化这些协议，以实现持续改进。
