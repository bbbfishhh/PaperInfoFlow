# 【资料整合】私有化部署 + 知识库

谁为AI买单？

1. 各大模型API（火山引擎、openrouter等）
2. AI编程 Cursor，Trae 的会员
3. 你或者你的身边有私有化部署的需求吗？
4. AI 陪伴APP（星野）的会员
5. 企业中的工具付费
6. AI 法律工具付费
7. AI 科研付费
8. AI 绘画即梦、海螺 付费
9. AI SEO 付费
10. AI 健康
11. 其他

 
## 政务 AI
对应问题以及策略

插入链接:https://mp.weixin.qq.com/s/MeXCwO3uebiLvOLDOr3soA



## 法律文件 -- 私有化 + RAG
https://mp.weixin.qq.com/s/QtXqrmKNyB3R-H8OIAxkqA
不要盲目再使用DeepSeek R1和QWQ这些推理模型做RAG了


**核心结论**：RAG系统需遵循"专用模型各司其职"原则，Qwen2-7B负责高效检索，推理模型DeepSeek R1专注复杂推理生成，配合工程优化实现高精度法律问答。该方案在15,000法律文档场景验证，显著提升检索相关性和回答可信度。

我们在大量法律文件数据集的基础上构建了 RAG，具体技术栈是：
- 使用 Qwen2-7B 嵌入用于检索；
- ChromaDB 作为用于存储嵌入存储和查询的向量存储；
- DeepSeek R1 生成最终答案。

工程开源总结：
- https://github.com/skypilot-org/skypilot/tree/master/llm/rag
- https://blog.skypilot.co/deepseek-rag/


## RAG 调优心法
https://mp.weixin.qq.com/s/ONwFKi5JE58cUl4RzzRcug

#### **实战工具链推荐**
1. **向量模型**
   - bge-m3（支持多粒度Prompt微调）
   - 领域适配：法律/医疗等垂直领域需微调（1000+标注数据）

2. **检索框架**
   - Elasticsearch + Hybrid Search插件（混合查询）
   - FAISS + HNSW（十亿级向量检索）

3. **Query优化**
   - Query2Doc技术（用LLM扩展检索词）
   - 关键词抽取（TextRank+TF-IDF）

#### **效果验证指标**
| 模块          | 核心指标                  | 达标阈值 |
|---------------|--------------------------|---------|
| 召回          | MRR@10 >0.65            | 0.7     |
| 精排          | NDCG@5 >0.8             | 0.85    |
| 生成          | 引用准确率 >90%          | 95%     |
| 端到端        | 人工评估通过率 >80%      | 85%     |

#### **典型误区警示**
- ❌ 盲目增加切片数量（导致检索噪声上升）
- ❌ 过度依赖向量召回（忽视BM25的精准匹配优势）
- ❌ 直接微调大模型（可能降低知识忠诚度）
- ❌ 无阈值控制（低质结果进入生成阶段）


## 企业私有化 + 条款RAG
qwen2.5 8b  nvidia 8g显存 简易知识库检索

![alt text](7a6b7d82912259d4b410a9a6aed21c3.png)

### 
https://mp.weixin.qq.com/s/7ab2--O83nMjWJrW4KR7ug
- 1、做好知识治理，保证高质量文档的输入，包括QA对；
- 2、做好用户问题重构；
- 3、选择更好的向量化模型；
- 4、引入混合检索；
- 5、分场景使用不同的重排算法；
- 6、使用更好的基础大模型；
- 7、再辅以合适的工程实施方法。


## GPU 列表

| GPU型号       | 主要作用          | 云单价($/h) | 市场价($) | 显存容量 | 关键备注                     |
|--------------|-------------------|------------|-----------|----------|------------------------------|
| **A100**     | AI训练/推理       | 2.9        | 12k-15k   | 40/80GB  | 二手企业卡，出口管制特供版   |
| **H100**     | 大规模训练        | 4.8        | 50k+      | 80GB     | Hopper架构，支持多卡互联     |
| **T4**       | 轻量推理          | 0.4        | 1.5k      | 16GB     | 云服务主力卡，支持MIG        |
| **A10**      | 多任务推理        | 0.6        | 4k        | 24GB     | 企业批量采购含维保           |
| **L4**       | 边缘推理          | 0.7        | 2.5k      | 24GB     | vLLM优化，适配法律文本       |
| **昇腾910B** | 国产AI计算        | -          | 8k        | 32GB     | 国产信创适配，华为MindSpore  |
| **风华GPU**  | 垂直领域推理      | -          | 5k-8k     | 24GB     | 国产化框架优化               |
| **MI250X**   | 高性能计算        | 1.5        | 10k-12k   | 128GB    | ROCm生态，英国超算采用       |
| **A30**      | 政务云推理        | 0.8        | 5.5k      | 24GB     | MIG多实例分割                |
| **RTX 4090** | 轻量开发          | 0.3        | 1.6k      | 24GB     | 消费级替代，仅限研发测试     |
| **RTX 4060** | 8B模型推理        | 0.3        | 400       | 12GB     | 全新卡，支持4bit量化部署      |
| **P106-100** | 轻量级7B/8B部署  | -          | 15        | 6GB      | 二手矿卡，需搭配系统内存扩展  |
| **RTX 3090** | 8B-14B模型推理    | 0.8        | 1,200     | 24GB     | 支持vLLM优化，推理速度50+ token/s |
| **RX 7600**  | AMD平台8B部署    | -          | 300       | 8GB      | 需安装Adrenalin 25.1.1驱动    |
| **RTX 3070** | 性价比8B部署     | 0.5        | 350       | 8GB      | 需搭配模型量化技术使用         |

