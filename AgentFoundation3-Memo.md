# Memory 记忆

从婴儿期开始，我们编码、存储和检索信息的能力支撑了我们学习语言、掌握技能和建立关系的能力。数十年的神经科学和认知心理学研究揭示了记忆的多方面作用，展示了它对自我意识、创造性活动和决策过程的影响。

## 人类记忆概述

人类记忆通常被概念化为一个多层次系统，能够在不同的处理水平和时间尺度上捕捉、存储和检索信息。

如图所示：

感知记忆、短期记忆、长期记忆（三者非严格隔离，有重叠）

感知，即随时随地的输入，触觉、听觉、视觉等

人的长期记忆，分为显性 和 非显性。

显性记忆：

涉及有意识的回忆，类似于人类的陈述性记忆。它包括语义记忆（存储常识性知识，如事实和概念）和情景记忆（记录特定事件和交互历史）。

- 语义记忆：关于世界的常识性知识，包括概念、词汇及其关系[182]。例如，回忆词汇的意义或知道一个国家的首都。
- 情景记忆：个人经历的事件，保留了时间、地点和相关人员的背景细节[183]。这种记忆形式使个体能够在心理上“穿越”回过去，重温过去的经历。
- 自传记忆：一种情景记忆，专注于与个人历史相关的事件和经历[184]。虽然有时被视为情景记忆的一个子类别，但自传记忆特别强调自我及其不断演变的人生叙事。

比如快速记忆法，或者说记忆宫殿法，其实就是将原本毫无关联的信息，对应到自己日常生活的情景当中，从而达成短暂的长期记忆能力。

例如，在TextWorld环境中，语义记忆捕获结构化事实，如“食谱 - 包含 - 金枪鱼”或“食谱 - 在 - 桌上”。相比之下，情景记忆记录情境语境和顺序动作，如“从厨房到客厅，再到花园”。整合语义和情景记忆使代理能够保留静态和语境信息，支持类人的适应性和语境感知响应。

另一方面，隐性记忆通过程序记忆和启动效应塑造代理行为。程序记忆使代理能够通过回忆特定技能和可重用计划高效执行重复任务。例如，它无需明确指令即可自动化常规任务，提高任务执行效率。

隐形记忆，则是习惯，条件反射等，通过习惯养成从而达成长期效果。

- 程序记忆：通过重复逐渐获得的运动技能和习惯（例如，骑自行车、键盘打字），这些技能会变得自动化[186, 187]。
- 启动效应：先前接触某刺激会影响后续反应，通常没有对之前接触的明确认知[188]。
- 经典条件反射：两个刺激之间的习得关联，其中一个刺激开始引发原本由另一个刺激引发的反应[189]。
- 非关联记忆：单一刺激反复暴露后行为的适应性改变。习惯化（对重复无害刺激的反应减少）和敏感化（暴露于有害或强烈刺激后反应增强）是典型例子[190, 191]。

【思考】那么如果要培养长期的多元思维模型习惯，需要靠隐性记忆，也就是习惯来实现，而习惯培养的天数其实不是 21 天，之前刷到过， 是至少60天。
然后根据福格行为模型，养成习惯，一开始需要最小化阻力，以及设计一条顺理成章、自然而然的路径。

如果我需要培养多元思维，先从重要学科的一个学科开始。
比如 5月，先简单看一个概率论入门书籍，写5篇公众号，然后短期记忆一些重要原则。

通过观察与运用，每天散步的时候进行思考，随手发朋友圈，即刻。之后和朋友反馈，碰撞，然后再写在公众号。

### 人类记忆模型

1. The Multi-Store (Modal) Model.多存储（模态）模型

2. Working Memory Models.工作记忆模型。 

认识到短期记忆还涉及信息的主动维持

3. Serial-Parallel-Independent (SPI) Model 串行-并行-独立（SPI）模型

区分了情景记忆、语义记忆和程序记忆

4. Global Workspace Theory (GWT) and the IDA/LIDA Framework.

全局工作空间理论（GWT）将意识和工作记忆概念化为一种“广播”机制，将信息分发给专门的处理器。

5. ACT-R and Cognitive Architectures.ACT-R与认知架构

ACT-R（适应性思维控制—理性）[199] 是一个综合的认知架构，将记忆、感知和运动过程整合到一个统一的理论框架中.




## 从人类记忆 到 Agent 记忆：

基于LLM的代理需要一个专门的记忆模块至关重要。虽然外部知识库（数据库、搜索引擎、API）[200] 提供了有价值的信息，但它们无法捕捉代理的内部推理、部分推断或特定任务的语境。一个代理记忆系统能够内化中间步骤、演变的目标和历史对话，使代理能够进行自我参照探索和适应。这对于需要代理在先前判断基础上构建或维持对用户目标个性化理解的任务至关重要。

### 早期代理记忆方法及其局限性

早期代理记忆方法，例如将对话历史附加到输入提示（一种初级的工作记忆形式）[201]，已经得到了演进。现代架构采用了更复杂的技术，包括使用向量嵌入来快速检索记忆[202]，以及选择性地将推理链纳入后续推理步骤[203, 204]。这些多样化的方法共享一个共同目标：管理庞大的信息库，同时不损害系统的响应能力。

人类工作记忆中存储知识与持续处理之间的灵活、双向互动在代理系统中往往缺失。元认知监督——选择性回忆、遗忘以及对过时信息的警惕——在基于LLM的代理中也尚未充分发展。

为基于LLM的代理构建强大且适应性强的记忆需要解决三个核心研究问题：
- 首先，记忆应如何表示，以捕捉多样化的信息类型并促进高效访问？
- 其次，代理记忆如何演变，融入新经验、适应变化的语境并保持一致性？
- 最后，存储的记忆如何有效增强推理、决策和整体代理性能？

### 感知记忆

形式上，感觉记忆的形成包括三个连续步骤：感知编码、注意力选择和瞬时保留。

扩展到超越基于文本的感知，多模态感觉记忆系统如 Jarvis-1 [228]、VideoAgent [209] 和 WorldGPT [210] 集成了多模态基础模型来处理多样化的模态输入。

### 短期记忆

在受认知启发的智能代理中，短期记忆作为一个短暂且动态的工作空间，连接感觉记忆与长期记忆。

智能代理中的短期记忆可分为语境记忆和工作记忆。一方面，语境记忆将语境窗口视为大语言模型（LLM）的短期记忆。例如，MemGPT [214] 受操作系统中层次记忆系统的启发，管理不同存储层以扩展超越LLM固有限制的语境。[290] 引入了一种神经符号语境记忆，通过支持符号规则 grounding 和基于LLM的规则应用来增强LLM。

另一方面，工作记忆涉及获取和整合相关外部知识，以在代理操作期间保留关键信息。生成代理（Generative Agent）[50] 使用短期记忆保留情境语境，促进语境敏感的决策。Reflexion [48] 利用滑动窗口机制捕捉和总结近期反馈，平衡详细的即时体验与高层次抽象，以提高适应性。RLP [218] 维护对话中说话者和听者的状态，将其作为短期记忆提示，以支持对话理解和生成。

### 长期记忆

在受认知启发的智能代理中，长期记忆支持信息的长期保留和检索，使代理能够有效泛化知识并适应新语境。与处理瞬时或即时数据的感觉记忆和短期记忆不同，长期记忆支持累积学习和跨任务适应性。

大多数智能代理在其记忆模块中实现了语义和情景记忆。例如，Agent S [211] 针对GUI自动化任务，将语义记忆以自然语言形式存储在线网络知识，而情景记忆捕获高层次、逐步的任务体验。类似地，AriGraph [221] 针对具身模拟任务，使用事实图编码语义环境知识，并通过事件图记录情景导航历史。在人工智能伴侣系统如 SiliconFriend 的 MemoryBank [207] 中，语义记忆以自然语言构建用户画像，而情景记忆保留交互历史，增强个性化和语境感知行为。

对于隐性记忆的实现，当前代理系统主要采用模型友好的记忆格式，如键值对存储、可执行代码或可重用例程。例如，AAG [226] 通过类比定义和泛化程序，将知识从一种情况（基础）映射到另一种情况（目标）。这种结构可以表示为线性有向链图，其中输入作为根节点，输出作为叶节点，每个中间步骤作为链中的节点。类似地，Cradle [227] 和 Jarvis-1 [228] 通过以代码形式存储和检索技能来实现程序记忆，这些技能可以从头学习或预定义。一旦整理好，技能可以添加、更新或在记忆中组合。然后检索与给定任务和语境最相关的技能以支持动作规划。


## 记忆生命周期
生命周期包括保留和检索的双重过程。保留包括获取、编码和推导，而检索涉及记忆匹配、神经记忆网络和记忆利用。


记忆获取是智能代理从环境中摄取原始感知信息的基础过程。

记忆获取的核心不仅是捕捉数据，还要启动初步的过滤过程。这一过滤利用两种主要机制：初始信息压缩和经验巩固。


【思考】记性好的前提是忘性好。

在早期阶段，信息压缩涉及使用基本技术来降低数据维度。这可能包括对图像进行下采样、使用简单启发式方法从文本中提取关键短语，或识别音频流中的重大变化[306]。目标是进行快速、有损压缩，以优先处理潜在相关的信息。例如，LMAgent [230] 提示大语言模型（LLM）进行信息压缩，在构建感觉记忆时减少无关和不重要的内容，以提高操作效率。同时，ReadAgent [231] 和 GraphRead [307] 分别采用不同的长文本压缩策略，即情节分页和基于图的结构化，以在确保效率的同时最大化信息保留。

另一方面，即使在获取阶段，经验巩固也发挥了作用。代理尚未拥有丰富的记忆，但可以开始应用先前学习的非常通用的规则或偏见。


### 记忆编码

编码的一个关键方面是选择性过滤。

编码的固有挑战源于原始感知数据的复杂性、高维度和常常带有的噪声特性。有效的编码需要高级机制来识别关键特征、紧凑压缩它们，并整合来自多种模态的信息。

现代方法通过利用选择性注意力和多模态融合来应对这些挑战。


多模态融合[310]对于整合来自不同感官输入的信息（例如，结合视觉和听觉数据以理解场景）至关重要。这涉及创建一个统一表示空间，其中来自不同模态的特征是对齐的。

通常使用跨模态编码器和对比学习技术来实现这种融合。例如，JARVIS-1 [228] 使用通用领域视频-语言模型 CLIP [51] 计算多模态键值记忆中的对齐，其中键包括任务、计划和视觉观察等元素，值是成功执行计划的文本表示。此外，Optimus-1 [241] 通过利用 MineCLIP [311]（一个在Minecraft游戏中预训练的领域特定视频-语言模型）优化多模态编码器，细化记忆表示，将过滤后的视频流与文本指令和计划对齐和融合，将代理的多模态体验编码到抽象的记忆池中。这种集成表示增强了跨模态的信息检索和推理，并作为另一个过滤器，强化一致的数据。


### 记忆推导
记忆推导专注于从获取和编码的记忆中提取有意义的知识和见解。

推导中的一个重大挑战是对信息价值的动态评估。应对这些挑战的策略包括反思、总结、知识蒸馏和选择性遗忘。


### 记忆检索与匹配
一个全面的方法可以应对这些挑战，包括四个关键组件。首先，构建统一的记忆表示和索引方案是基础步骤。这旨在通过将不同类型的记忆嵌入到公共向量空间中，弥合它们之间的表示差距。可以使用预训练语言模型（如BERT或Sentence-BERT [316]）将基于文本的记忆转化为语义向量，而图神经网络（GNNs）可以为结构化记忆（如知识图谱）学习向量表示，捕捉节点和边的关系[317]。为促进高效检索，多层次混合索引结构至关重要。这集成了倒排索引用于关键词匹配、Faiss [318] 或 Annoy [319] 等向量索引用于相似性搜索，以及图索引用于结构化查询[320]，从而支持多样化的查询需求。

其次，最关键的是，系统必须开发语境感知的语义相似性计算。这使检索过程能够理解并利用当前语境，如代理的状态、目标和观察结果，从而实现超越关键词重叠的更深层语义匹配。这涉及将语境信息编码为向量表示，并将其与记忆向量有效融合。注意力机制在此发挥了关键作用，动态计算语境与记忆向量之间的相关性，并根据语境相关性为记忆片段分配不同的权重[261]。这强调了与当前情境更相关的记忆。

### 神经记忆网络

神经记忆网络是人工智能研究中的一个引人注目的前沿领域。它们旨在将记忆无缝整合到神经网络的结构中。这种方法偏离了传统记忆架构，通过直接在网络的权重或激活中编码记忆，将网络转变为动态的读写记忆存储介质。这种紧密整合有望在效率和存储信息利用方面取得重大进展。然而，实现这一愿景面临若干重大挑战。

一个主要问题是平衡记忆容量与稳定性。在神经网络有限参数中编码大量信息，同时保持长期稳定性，是一个重大障碍。

一方面，受大脑神经元互联性的启发，关联记忆提供了一条有前景的途径。像Hopfield网络[262, 263]（利用能量函数）和双向关联记忆（BAMs）[322]（支持异关联回忆）等模型提供了基于神经元间权重编码和检索模式的机制。此外，神经图灵机（NTMs）[264]和记忆增强神经网络（MANNs）[323, 324, 275, 265]通过外部记忆模块增强神经网络，采用注意力和总结机制与这些记忆交互。

### 记忆利用

代理设计的一个关键方面在于记忆利用，重点是最大化存储记忆片段对当前任务的价值。其核心目标是有效且适当地应用这些记忆，以增强推理、决策、规划和动作生成，最终提升代理的性能和效率，同时避免无关或错误记忆干扰的陷阱。

一个主要挑战是平衡记忆存储的庞大性与其有效利用。代理必须应对潜在的信息过载，确保充分利用相关记忆而不使系统不堪重负。

另一个障碍是对抽象和泛化的需求。代理需要将特定记忆片段提炼为更通用的知识，并将这些知识应用于新的多样化情境。此外，大语言模型内部的幻觉和错误记忆问题需要仔细考虑。防止生成与存储信息矛盾或错误的内容至关重要，同样重要的是识别和纠正记忆存储中可能存在的错误信息。

为应对这些挑战，采用了若干策略。检索增强生成（RAG）[334]结合检索和生成模型，通过利用外部知识源增强大语言模型的能力。与记忆检索和匹配中提到的方法不同，RAG专注于将检索到的信息整合到生成过程中。当收到提示时，代理检索相关记忆片段并将其融入生成模型提供的语境中。这种语境丰富化引导模型生成更具事实依据和信息量的输出。例如，在响应用户查询时，代理可以首先从其知识库中检索相关条目，然后基于这些检索信息生成答案，从而使回答基于已建立的知识。最近，一些研究将记忆模块与RAG整合，加入了自我反思[274]和适应性检索机制[272]，以提升生成可靠性和效率。例如，Atlas [273] 利用因果中介分析，而[284] 采用基于一致性的幻觉检测，判断模型是否已具备所需知识（允许直接生成），还是需要检索（在生成前先检索相关信息）。在一个统一的框架中，RAGLAB [271] 提供了评估和分析主流RAG算法的综合生态系统。HippoRAG [222] 采用受人类记忆海马索引理论启发的策略，创建基于知识图谱的记忆索引，并使用个性化PageRank进行记忆检索。

此外，长语境建模在管理庞大记忆存储方面发挥了重要作用。这种方法增强了大语言模型处理长序列和大规模记忆的能力，允许更深入地理解和利用长程依赖关系。通过采用Transformer模型变体，如Transformer-XL [324] 和 Longformer [335]，或通过层次化和递归处理技术，如循环记忆变换器（RMT）[275, 276]，代理可以扩展其语境窗口。这使其能够处理更广泛的记忆存储，并在更广阔的语境中进行推理和决策。例如，代理在处理冗长文档或进行长时间对话时可以保持更长的记忆跨度。此外，一些研究利用记忆压缩长语境，以实现更有效的长语境建模。例如，AutoCompressor [277] 引入摘要向量作为记忆，将先前语境窗口的信息传递到当前窗口，促进长语境理解。类似地，上下文自编码器（ICAE）[278] 生成准确且全面表示原始语境的记忆槽，而 LLMLingua [336, 337]、Gist [279] 和 CompAct [280] 进一步优化长提示压缩，以减少输入语境长度。

最后，幻觉缓解策略对于确保生成输出的可靠性至关重要。这些策略旨在最大程度减少大语言模型生成事实错误或无意义内容的倾向。一种方法是实现事实核查机制[338]，验证生成内容与已建立的知识或记忆存储的一致性。另一种方法涉及不确定性估计[339, 340]，模型评估其生成内容的置信度，并标记或过滤低置信度输出。此外，在生成阶段可以采用基于知识的解码策略，引入约束以引导模型生成更符合事实的内容。这些技术共同有助于生成更可信的输出，并与代理的已建立知识库保持一致。近期研究引入了专家记忆子网络，如 PEER [283] 和 Lamini Memory Tuning [281]，它们专门记忆特定类型的信息，包括世界知识和AI代理的过去经验。这些子网络将记忆任务卸载到专用参数，减少主模型产生幻觉的倾向。通过实施这些记忆利用策略，代理可以变得更强大、准确和可靠。它们能够成功利用其记忆存储，在复杂任务中实现卓越性能。

## 总结

强大的世界模型对于高级认知、规划和类人智能至关重要。世界模型本质上是一种高度结构化、通常具有预测性的长期记忆形式。

人类记忆具有惊人的关联性，能够从不完整或噪声线索中检索信息，并展现出一种复杂的“遗忘”形式，涉及巩固和抽象，优先考虑相关信息并从经验中泛化。

几个有前景的研究方向浮现。探索受生物启发的机制，如神经记忆网络（正如前文讨论的），可能带来重大突破。

另一个关键领域是开发主动“管理”其内容的记忆系统——反思信息、识别不一致性并合成新知识。这需要将元认知能力（监控和控制自身认知过程）整合到代理架构中。

此外，创建更强大且细致的场景记忆形式，不仅捕捉“是什么”和“何时”，还包括“为什么”以及事件的情感语境，对于能够真正从经验中学习并与人类自然交互的代理至关重要。

克服这些挑战需要在深度学习、强化学习和认知科学的交叉处寻找创新解决方案。

开发更复杂和适应性的世界模型和记忆系统——那些反映人类认知优势的系统——将为代理更深入地理解其环境铺平道路，从而实现更智能和有意义的交互。